name: Lighthouse Performance Audit
on:
  issue_comment:
    types: [created]
jobs:
  lighthouse-audit:
    # Only run on PR comments that contain the trigger phrase
    if: github.event.issue.pull_request && contains(github.event.comment.body, 'RUN_COMMIT_CRAB')
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      issues: write
    steps:
      - name: React to trigger comment
        uses: actions/github-script@v8
        with:
          script: |
            github.rest.reactions.createForIssueComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: context.payload.comment.id,
              content: 'rocket'
            });
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          token: ${{ secrets.GITHUB_TOKEN }}
      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: "22"
      - name: Install dependencies and build project
        run: |
          # Install system-level tools
          sudo apt-get update
          sudo apt-get install -y jq
          # Navigate to dashboard directory and install dependencies
          cd dashboard
          # Install Bun package manager
          curl -fsSL https://bun.sh/install | bash
          export BUN_INSTALL="$HOME/.bun"
          export PATH="$BUN_INSTALL/bin:$PATH"
          # Install project dependencies
          bun install
          # Create a production build of the project
          bun run build
          # Navigate back to root and install global tools for the audit
          cd ..
          npm install -g lighthouse
          npm install -g http-server
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@v2
        with:
          chrome-version: stable
          install-dependencies: true
      - name: Start local server for PR build
        run: |
          # Start a local HTTP server in the background, serving the dashboard build folder.
          # Vite typically builds to 'dist' directory
          http-server ./dashboard/dist -p 8080 -c-1 --cors &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          # Wait for server to start
          sleep 5
          # Check if server is running and list available files for debugging
          echo "Testing server..."
          curl -f http://localhost:8080/ || echo "Server check failed"
          echo "Available files via HTTP:"
          curl -s http://localhost:8080/ | grep -o 'href="[^"]*\.html[^"]*"' || echo "No HTML files served"
      - name: Extract URL for audit
        id: extract-url
        uses: actions/github-script@v8
        with:
          script: |
            const comment = context.payload.comment.body;
            // Look for an external URL in the comment
            const urlMatch = comment.match(/RUN_COMMIT_CRAB\s+(https?:\/\/[^\s]+)/i);
            let targetUrl = 'http://localhost:8080/'; // Default to the locally hosted build
            if (urlMatch && urlMatch[1]) {
              targetUrl = urlMatch[1];
            }
            core.setOutput('url', targetUrl);
            core.setOutput('is_local', targetUrl.includes('localhost') ? 'true' : 'false');
            console.log('Target URL:', targetUrl);
            console.log('Is local file:', targetUrl.includes('localhost'));
      - name: Run Lighthouse Audit
        id: lighthouse
        run: |
          TARGET_URL="${{ steps.extract-url.outputs.url }}"
          echo "Running Lighthouse audit on: $TARGET_URL"
          # First, test if the URL is reachable
          echo "Testing URL accessibility..."
          if curl -f "$TARGET_URL" -o /dev/null -s; then
            echo "‚úÖ URL is accessible"
          else
            echo "‚ùå URL is not accessible, trying without -f flag..."
            curl -v "$TARGET_URL" -o /dev/null || echo "URL completely unreachable"
          fi
          # Run lighthouse with better error handling
          echo "Running Lighthouse..."
          if lighthouse_raw=$(lighthouse "$TARGET_URL" \
            --output=json \
            --quiet \
            --chrome-flags="--headless --no-sandbox --disable-dev-shm-usage" 2>&1); then
            
            echo "‚úÖ Lighthouse completed successfully"
            echo "Raw output preview (first 500 chars):"
            echo "$lighthouse_raw" | head -c 500
            
            # Parse with jq and handle errors
            if lighthouse_output=$(echo "$lighthouse_raw" | jq '{
              FCP: .audits["first-contentful-paint"].displayValue,
              LCP: .audits["largest-contentful-paint"].displayValue,
              CLS: .audits["cumulative-layout-shift"].displayValue,
              TBT: .audits["total-blocking-time"].displayValue,
              TTI: .audits["interactive"].displayValue,
              Performance: .categories.performance.score
            }' 2>/dev/null); then
              echo "‚úÖ Successfully parsed Lighthouse results"
            else
              echo "‚ùå Failed to parse Lighthouse JSON, creating fallback result"
              lighthouse_output='{"FCP": "N/A", "LCP": "N/A", "CLS": "N/A", "TBT": "N/A", "TTI": "N/A", "Performance": 0, "error": "Parse error"}'
            fi
          else
            echo "‚ùå Lighthouse failed to run"
            echo "Lighthouse error output:"
            echo "$lighthouse_raw"
            lighthouse_output='{"FCP": "N/A", "LCP": "N/A", "CLS": "N/A", "TBT": "N/A", "TTI": "N/A", "Performance": 0, "error": "Lighthouse failed"}'
          fi
          echo "lighthouse_results<<EOF" >> $GITHUB_OUTPUT
          echo "$lighthouse_output" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "target_url<<EOF" >> $GITHUB_OUTPUT
          echo "$TARGET_URL" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          # Also save to a file for debugging
          echo "$lighthouse_output" > lighthouse-results.json
          cat lighthouse-results.json
      # New AI PR Review steps
      # -------------------------------
      - name: Get PR Diff
        id: get_diff
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          DIFF_CONTENT=$(gh pr diff --color never "${{ github.event.issue.number }}")

          if [ -z "$DIFF_CONTENT" ]; then
            echo "Diff is empty. Setting a placeholder message for the AI."
            DIFF_CONTENT="No code changes detected in this PR."
          fi

          echo "diff<<EOF" >> "$GITHUB_OUTPUT"
          echo "$DIFF_CONTENT" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
      - name: Call OpenAI for PR Suggestions
        id: openai
        env:
          LIGHTHOUSE_JSON: ${{ steps.lighthouse.outputs.lighthouse_results }}
        run: |
          DIFF_CONTENT="${{ steps.get_diff.outputs.diff }}"

          # Use jq to safely build the JSON payload, including both the diff and the Lighthouse results.
          JSON_PAYLOAD=$(jq -n \
            --arg diff "$DIFF_CONTENT" \
            --arg lighthouse "$LIGHTHOUSE_JSON" \
            '{
              "model": "gpt-4o-mini",
              "messages": [
                {
                  "role": "system", 
                  "content": "You are an expert performance engineer. Your task is to analyze a pull request'\''s code changes (diff) in conjunction with its Lighthouse performance report. Identify potential causes for poor performance scores in the code and suggest specific, actionable optimizations."
                },
                {
                  "role": "user", 
                  "content": ("Here are the Lighthouse performance results:\n\n" + $lighthouse + "\n\nHere is the code diff that produced these results:\n\n" + $diff + "\n\nBased on the Lighthouse report (especially metrics like LCP, TBT, CLS), analyze the code diff and provide specific, actionable suggestions to improve performance.")
                }
              ]
            }')
            
          RESPONSE=$(curl -s https://api.openai.com/v1/chat/completions \
            -H "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}" \
            -H "Content-Type: application/json" \
            -H "OpenAI-Project: ${{ secrets.OPENAIPROJECT }}" \
            -d "$JSON_PAYLOAD")
            
          echo "review=$(echo "$RESPONSE" | jq -r '.choices[0].message.content')" >> $GITHUB_OUTPUT
      - name: Comment PR with AI Review
        uses: actions/github-script@v8
        with:
          script: |
            const review = `${{ steps.openai.outputs.review }}`;
            const body = `## ü§ñ AI Performance Analysis
            ${review}`;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body
            });
      - name: Comment PR with results
        uses: actions/github-script@v8
        with:
          script: |
            const results = JSON.parse(`${{ steps.lighthouse.outputs.lighthouse_results }}`);
            // Calculate performance score percentage
            const perfScore = Math.round((results.Performance || 0) * 100);
            // Determine performance grade
            let grade = 'üî¥';
            if (perfScore >= 90) grade = 'üü¢';
            else if (perfScore >= 50) grade = 'üü°';
            // Check if there was an error
            const hasError = results.error || perfScore === 0;
            const comment = `## ü¶Ä Commit Crab Lighthouse Results ${hasError ? '‚ö†Ô∏è' : grade}
            **Performance Score: ${perfScore}/100**
            ${results.error ? `\n‚ö†Ô∏è **Error**: ${results.error}` : ''}
            ${results.Performance && results.Performance > 0 ? '' : '\n‚ö†Ô∏è *Note: This might be a local file test or there was an issue*'}
            ### Core Web Vitals
            | Metric | Value |
            |--------|--------|
            | **First Contentful Paint (FCP)** | ${results.FCP || 'N/A'} |
            | **Largest Contentful Paint (LCP)** | ${results.LCP || 'N/A'} |
            | **Cumulative Layout Shift (CLS)** | ${results.CLS || 'N/A'} |
            | **Total Blocking Time (TBT)** | ${results.TBT || 'N/A'} |
            | **Time to Interactive (TTI)** | ${results.TTI || 'N/A'} |
            ### Performance Recommendations
            ${hasError ? '‚ùå Unable to analyze performance due to errors. Check if the URL is accessible.' :
              perfScore >= 90 ? '‚úÖ Excellent performance! Keep up the good work.' :
              perfScore >= 50 ? '‚ö†Ô∏è Good performance, but there\'s room for improvement.' :
              '‚ùå Performance needs attention. Consider optimizing critical resources.'}
            ${`${{ steps.extract-url.outputs.is_local }}` === 'true' ? 
              '### üìÅ PR File Testing\n‚úÖ This test was run against the **production build** of your Pull Request!\n' : ''}
            ${hasError ? 
              '### üîß Troubleshooting\n- Ensure your dashboard\'s build command (`bun run build`) is working.\n- Check if the build output directory (`./dashboard/dist`) exists.\n- Verify that the built application runs without errors.\n' : ''}
            ---
            *Triggered by: @${{ github.event.comment.user.login }}*
            *URL tested: ${{ steps.lighthouse.outputs.target_url }}*
            *Commit: ${{ github.event.pull_request.head.sha || 'N/A' }}*
            `;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-results
          path: lighthouse-results.json
          retention-days: 30

      - name: Calculate Bundle Sizes
        id: bundle-sizes
        run: |
          echo "Calculating bundle sizes from build directory..."

          # Navigate to the build directory
          cd dashboard/dist

          # Calculate sizes in KB for different file types (using Linux stat command)
          JS_SIZE=$(find . -name "*.js" -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')
          CSS_SIZE=$(find . -name "*.css" -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Image files (jpg, jpeg, png, gif, svg, webp, ico)
          IMAGES_SIZE=$(find . \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -o -name "*.gif" -o -name "*.svg" -o -name "*.webp" -o -name "*.ico" \) -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Other files (excluding js, css, images)
          OTHERS_SIZE=$(find . ! \( -name "*.js" -o -name "*.css" -o -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -o -name "*.gif" -o -name "*.svg" -o -name "*.webp" -o -name "*.ico" \) -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Total build size
          TOTAL_SIZE=$(find . -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Handle empty values (set to 0 if no files found)
          JS_SIZE=${JS_SIZE:-0}
          CSS_SIZE=${CSS_SIZE:-0}
          IMAGES_SIZE=${IMAGES_SIZE:-0}
          OTHERS_SIZE=${OTHERS_SIZE:-0}
          TOTAL_SIZE=${TOTAL_SIZE:-0}

          echo "Bundle size breakdown:"
          echo "JavaScript: ${JS_SIZE} KB"
          echo "CSS: ${CSS_SIZE} KB"
          echo "Images: ${IMAGES_SIZE} KB"
          echo "Others: ${OTHERS_SIZE} KB"
          echo "Total: ${TOTAL_SIZE} KB"

          # Set outputs for the next step
          echo "js_size=${JS_SIZE}" >> $GITHUB_OUTPUT
          echo "css_size=${CSS_SIZE}" >> $GITHUB_OUTPUT
          echo "images_size=${IMAGES_SIZE}" >> $GITHUB_OUTPUT
          echo "others_size=${OTHERS_SIZE}" >> $GITHUB_OUTPUT
          echo "total_size=${TOTAL_SIZE}" >> $GITHUB_OUTPUT

          # Also create a detailed file listing for debugging
          echo "Detailed file listing:"
          find . -type f -exec ls -lh {} \; | sort -k5 -hr | head -20

      - name: Generate PR Performance JSON
        id: generate-json
        uses: actions/github-script@v8
        with:
          script: |
            // Parse lighthouse results
            const lighthouseResults = JSON.parse(`${{ steps.lighthouse.outputs.lighthouse_results }}`);

            // Get PR details from GitHub API
            const prData = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });

            // Get PR files changed
            const filesChanged = await github.rest.pulls.listFiles({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });

            // Extract vitals from lighthouse results (convert to numbers)
            const extractValue = (value) => {
              if (!value || value === 'N/A') return 0;
              // Extract numeric value from strings like "1.2 s" or "150 ms"
              const match = value.toString().match(/[\d.]+/);
              return match ? parseFloat(match[0]) : 0;
            };

            const vitals = {
              lcp: extractValue(lighthouseResults.LCP),
              tbt: extractValue(lighthouseResults.TBT), 
              cls: extractValue(lighthouseResults.CLS),
              fcp: extractValue(lighthouseResults.FCP),
              si: 0, // Speed Index not captured in current setup
              tti: extractValue(lighthouseResults.TTI)
            };

            // Calculate average score (excluding SI since it's not available)
            const vitalsAvgScore = Math.round((lighthouseResults.Performance || 0) * 100);

            // Create the JSON structure with real PR data
            const prNumber = context.issue.number;
            const prPerformanceData = {
              [prNumber]: {
                prnumber: prNumber,
                title: prData.data.title || "PR Title Not Available",
                filesChanged: filesChanged.data.length || 0,
                prURL: prData.data.html_url || "",
                prDesc: prData.data.body || "",
                vitalsAvgScore: vitalsAvgScore,
                raisedBy: prData.data.user.login || "",
                PRCreatedOn: prData.data.created_at || "",
                reviewers: prData.data.requested_reviewers?.map(r => r.login) || [],
                vitals: vitals,
                bundleSize: {
                  js: parseInt(`${{ steps.bundle-sizes.outputs.js_size }}`) || 0,
                  css: parseInt(`${{ steps.bundle-sizes.outputs.css_size }}`) || 0,
                  images: parseInt(`${{ steps.bundle-sizes.outputs.images_size }}`) || 0,
                  others: parseInt(`${{ steps.bundle-sizes.outputs.others_size }}`) || 0
                },
                totalBuildSize: `${{ steps.bundle-sizes.outputs.total_size }} KB`
              }
            };

            console.log('Generated PR Performance Data:');
            console.log(JSON.stringify(prPerformanceData, null, 2));

            // Set output for the curl step
            core.setOutput('json_data', JSON.stringify(prPerformanceData));

      - name: Send Data to JSONBin
        run: |
          echo "Sending performance data to JSONBin..."

          # Get existing data first
          echo "Fetching existing data..."
          EXISTING_DATA=$(curl -v \
            -H "X-Access-key: \$2a\$10\$wF2lmZTq.Xrr1IRJd2Mbu.iYxaYo0Lswkx7ZE/kUuMUkq2fFxuI06" \
            --request GET \
            https://api.jsonbin.io/v3/b/68cd6b53d0ea881f40833212)

          echo "Raw existing data response:"
          echo "$EXISTING_DATA" | head -200

          # Extract the record data (JSONBin wraps data in metadata)
          EXISTING_RECORD=$(echo "$EXISTING_DATA" | jq -r '.record // {}')

          # Get new data from previous step
          NEW_DATA='${{ steps.generate-json.outputs.json_data }}'
          echo "New data to append:"
          echo "$NEW_DATA" | jq .

          # Append/merge the new PR data with existing records under the record key
          MERGED_RECORD=$(jq -n --argjson existing "$EXISTING_RECORD" --argjson new "$NEW_DATA" '$existing * $new')

          echo "Merged record data:"
          echo "$MERGED_RECORD" | jq .

          # Send the merged record data directly (JSONBin will automatically wrap it)
          RESPONSE=$(curl -v \
            -H "Content-Type: application/json" \
            -H "X-Access-key: \$2a\$10\$wF2lmZTq.Xrr1IRJd2Mbu.iYxaYo0Lswkx7ZE/kUuMUkq2fFxuI06" \
            --request PUT \
            --data "$MERGED_RECORD" \
            https://api.jsonbin.io/v3/b/68cd6b53d0ea881f40833212)

          echo "JSONBin Response:"
          echo "$RESPONSE" | jq .

          if echo "$RESPONSE" | jq -e '.record' > /dev/null; then
            echo "‚úÖ Performance data successfully sent to JSONBin"
          else
            echo "‚ùå Failed to send data to JSONBin"
            echo "Response details:"
            echo "$RESPONSE"
          fi

      - name: Cleanup
        if: always()
        run: |
          # Kill the local server if it's running
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID 2>/dev/null || echo "Server already stopped"
          fi