name: Lighthouse Performance Audit
on:
  issue_comment:
    types: [created]

jobs:
  lighthouse-audit:
    # Only run on PR comments that contain the trigger phrase
    if: github.event.issue.pull_request && contains(github.event.comment.body, 'RUN_COMMIT_CRAB')
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      issues: write

    steps:
      - name: React to trigger comment
        uses: actions/github-script@v8
        with:
          script: |
            github.rest.reactions.createForIssueComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: context.payload.comment.id,
              content: 'rocket'
            });

      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: "22"

      - name: Install dependencies and build project
        run: |
          # Install system-level tools
          sudo apt-get update
          sudo apt-get install -y jq

          # Navigate to dashboard directory and install dependencies
          cd dashboard

          # Install Bun package manager (fixed: plain URL, no Markdown link)
          curl -fsSL https://bun.sh/install | bash
          export BUN_INSTALL="$HOME/.bun"
          export PATH="$BUN_INSTALL/bin:$PATH"

          # Install project dependencies
          bun install

          # Create a production build of the project
          bun run build

          # Navigate back to root and install global tools for the audit
          cd ..
          npm install -g lighthouse
          npm install -g http-server

      - name: Start local server for PR build
        run: |
          # Start a local HTTP server in the background, serving the dashboard build folder.
          # Vite typically builds to 'dist' directory
          http-server ./dashboard/dist -p 8080 -c-1 --cors &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV

          # Wait for server to start
          sleep 5

          # Check if server is running and list available files for debugging
          echo "Testing server..."
          curl -f http://localhost:8080/ || echo "Server check failed"
          echo "Available files via HTTP:"
          curl -s http://localhost:8080/ | grep -o 'href="[^"]*\.html[^"]*"' || echo "No HTML files served"

      - name: Extract URL for audit
        id: extract-url
        uses: actions/github-script@v8
        with:
          script: |
            const comment = context.payload.comment.body;
            // Look for an external URL in the comment
            const urlMatch = comment.match(/RUN_COMMIT_CRAB\s+(https?:\/\/[^\s]+)/i);
            let targetUrl = 'http://localhost:8080/'; // Default to the locally hosted build
            if (urlMatch && urlMatch[1]) {
              targetUrl = urlMatch[1];
            }
            core.setOutput('url', targetUrl);
            core.setOutput('is_local', targetUrl.includes('localhost') ? 'true' : 'false');
            console.log('Target URL:', targetUrl);
            console.log('Is local file:', targetUrl.includes('localhost'));

      - name: Run Lighthouse Audit
        id: lighthouse
        run: |
          TARGET_URL="${{ steps.extract-url.outputs.url }}"
          echo "Running Lighthouse audit on: $TARGET_URL"

          # First, test if the URL is reachable
          echo "Testing URL accessibility..."
          if curl -f "$TARGET_URL" -o /dev/null -s; then
            echo "‚úÖ URL is accessible"
          else
            echo "‚ùå URL is not accessible, trying without -f flag..."
            curl -v "$TARGET_URL" -o /dev/null || echo "URL completely unreachable"
          fi

          # Run lighthouse with better error handling
          echo "Running Lighthouse..."
          if lighthouse_raw=$(lighthouse "$TARGET_URL" \
            --output=json \
            --quiet \
            --chrome-flags="--headless --no-sandbox --disable-dev-shm-usage" 2>&1); then

            echo "‚úÖ Lighthouse completed successfully"
            echo "Raw output preview (first 500 chars):"
            echo "$lighthouse_raw" | head -c 500

            # Parse with jq and handle errors
            if lighthouse_output=$(echo "$lighthouse_raw" | jq '{
              FCP: .audits["first-contentful-paint"].displayValue,
              LCP: .audits["largest-contentful-paint"].displayValue,
              CLS: .audits["cumulative-layout-shift"].displayValue,
              TBT: .audits["total-blocking-time"].displayValue,
              TTI: .audits["interactive"].displayValue,
              Performance: .categories.performance.score
            }' 2>/dev/null); then
              echo "‚úÖ Successfully parsed Lighthouse results"
            else
              echo "‚ùå Failed to parse Lighthouse JSON, creating fallback result"
              lighthouse_output='{"FCP": "N/A", "LCP": "N/A", "CLS": "N/A", "TBT": "N/A", "TTI": "N/A", "Performance": 0, "error": "Parse error"}'
            fi
          else
            echo "‚ùå Lighthouse failed to run"
            echo "Lighthouse error output:"
            echo "$lighthouse_raw"
            lighthouse_output='{"FCP": "N/A", "LCP": "N/A", "CLS": "N/A", "TBT": "N/A", "TTI": "N/A", "Performance": 0, "error": "Lighthouse failed"}'
          fi

          echo "lighthouse_results<<EOF" >> $GITHUB_OUTPUT
          echo "$lighthouse_output" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          echo "target_url<<EOF" >> $GITHUB_OUTPUT
          echo "$TARGET_URL" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          # Also save to a file for debugging
          echo "$lighthouse_output" > lighthouse-results.json
          cat lighthouse-results.json
      # New AI PR Review steps
      # -------------------------------
      - name: Get PR Diff
        id: get_diff
        run: |
          PR_URL="https://github.com/${{ github.repository }}/pull/${{ github.event.issue.number }}.diff"
          echo "Fetching diff from $PR_URL"
          # Use curl with authentication to fetch the diff, which works for private repos
          curl -s -L -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" "$PR_URL" > pr_diff.txt

          # Check if the diff file has content
          if [ ! -s pr_diff.txt ]; then
            echo "Diff is empty. Setting a placeholder message for the AI."
            echo "No code changes detected in this PR." > pr_diff.txt
          fi

          # Use a more robust method to set the output that handles special characters
          {
            echo "diff<<EOF"
            cat pr_diff.txt
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: Analyze Changed Files
        id: analyze_files
        uses: actions/github-script@v8
        with:
          script: |
            // Get PR files
            const filesChanged = await github.rest.pulls.listFiles({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });

            let fileAnalysis = "## üìÅ Files Changed Analysis\n\n";
            let totalLinesAdded = 0;
            let totalLinesRemoved = 0;
            let jsFiles = 0;
            let tsFiles = 0;
            let cssFiles = 0;
            let testFiles = 0;
            let configFiles = 0;

            for (const file of filesChanged.data) {
              totalLinesAdded += file.additions || 0;
              totalLinesRemoved += file.deletions || 0;
              
              const extension = file.filename.split('.').pop()?.toLowerCase();
              const isTest = file.filename.includes('.test.') || file.filename.includes('.spec.') || file.filename.includes('__tests__');
              const isConfig = file.filename.includes('config') || ['json', 'yml', 'yaml', 'toml'].includes(extension);
              
              if (extension === 'js' || extension === 'jsx') jsFiles++;
              else if (extension === 'ts' || extension === 'tsx') tsFiles++;
              else if (extension === 'css' || extension === 'scss' || extension === 'sass') cssFiles++;
              else if (isTest) testFiles++;
              else if (isConfig) configFiles++;

              fileAnalysis += `- **${file.filename}** (+${file.additions}/-${file.deletions}) - ${file.status}\n`;
            }

            fileAnalysis += `\n### üìä Change Summary\n`;
            fileAnalysis += `- **Total Lines Added:** ${totalLinesAdded}\n`;
            fileAnalysis += `- **Total Lines Removed:** ${totalLinesRemoved}\n`;
            fileAnalysis += `- **Net Change:** ${totalLinesAdded - totalLinesRemoved}\n`;
            fileAnalysis += `- **Files Modified:** ${filesChanged.data.length}\n\n`;

            fileAnalysis += `### üè∑Ô∏è File Type Breakdown\n`;
            fileAnalysis += `- **JavaScript Files:** ${jsFiles}\n`;
            fileAnalysis += `- **TypeScript Files:** ${tsFiles}\n`;
            fileAnalysis += `- **CSS/Style Files:** ${cssFiles}\n`;
            fileAnalysis += `- **Test Files:** ${testFiles}\n`;
            fileAnalysis += `- **Config Files:** ${configFiles}\n`;

            core.setOutput('file_analysis', fileAnalysis);
            core.setOutput('total_lines_added', totalLinesAdded);
            core.setOutput('total_lines_removed', totalLinesRemoved);
            core.setOutput('files_count', filesChanged.data.length);

      - name: Call OpenAI for PR Suggestions
        id: openai
        env:
          LIGHTHOUSE_JSON: ${{ steps.lighthouse.outputs.lighthouse_results }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_PROJECT: ${{ secrets.OPENAIPROJECT }}
        run: |
          # Read the diff content from file to handle special characters properly
          DIFF_CONTENT=$(cat pr_diff.txt)
          FILE_ANALYSIS="${{ steps.analyze_files.outputs.file_analysis }}"

          # Create a temporary JSON file to avoid shell escaping issues
          cat > request.json << 'EOL'
          {
            "model": "gpt-5",
            "messages": [
              {
                "role": "system",
                "content": "You are a Senior Engineering Developer with 15+ years of experience in frontend development, performance optimization, and code architecture. Your expertise spans React, TypeScript, modern build tools, and web performance best practices. You conduct thorough static code analysis focusing on:\n\n1. **Performance Impact**: Analyze how code changes affect Core Web Vitals (LCP, FCP, CLS, TBT, TTI)\n2. **Code Quality**: Review for maintainability, readability, and adherence to best practices\n3. **Architecture Patterns**: Suggest better structural approaches and design patterns\n4. **Security Considerations**: Identify potential security vulnerabilities\n5. **Scalability**: Evaluate how changes impact application scalability\n6. **Bundle Optimization**: Recommend strategies for reducing bundle size\n7. **Runtime Performance**: Identify potential memory leaks, inefficient algorithms, or blocking operations\n\nProvide detailed, actionable feedback with specific code suggestions, prioritized by impact level (High/Medium/Low). Include rationale for each recommendation and reference industry best practices."
              },
              {
                "role": "user",
                "content": "PLACEHOLDER_FOR_CONTENT"
              }
            ]
          }
          EOL

          # Escape the content for JSON and replace the placeholder
          CONTENT="## üìä Performance Metrics Analysis\n${LIGHTHOUSE_JSON}\n\n${FILE_ANALYSIS}\n\n## üìù Code Changes Review\n\`\`\`diff\n${DIFF_CONTENT}\n\`\`\`\n\n## üéØ Senior Developer Code Review Request\n\nAs a Senior Engineering Developer, please provide a comprehensive static code analysis of this pull request. Focus on:\n\n### üîç Static Code Analysis:\n1. **Code Quality & Maintainability**: Review code structure, naming conventions, and adherence to best practices\n2. **Performance Impact**: Correlate the code changes with the Lighthouse metrics above\n3. **Architecture Assessment**: Evaluate if the implementation follows solid architectural principles\n4. **Security Review**: Identify any potential security vulnerabilities or concerns\n5. **Bundle Size Impact**: Assess how these changes might affect the application bundle size\n\n### üìã Specific Areas to Review:\n- **React/TypeScript Best Practices**: Component design, type safety, hooks usage\n- **Performance Optimizations**: Lazy loading, code splitting, memoization opportunities\n- **Accessibility**: WCAG compliance and semantic HTML usage\n- **Testing Considerations**: Testability of the new code\n- **Documentation**: Code readability and inline documentation\n\n### üìä Deliverables:\nProvide your analysis in the following format:\n\n**üö® HIGH PRIORITY ISSUES** (if any)\n**‚ö†Ô∏è MEDIUM PRIORITY IMPROVEMENTS** (if any)\n**üí° LOW PRIORITY SUGGESTIONS** (if any)\n**‚úÖ POSITIVE OBSERVATIONS** (what's done well)\n**üéØ PERFORMANCE CORRELATION** (how code changes relate to Lighthouse scores)\n**üìö RECOMMENDED RESOURCES** (links to relevant best practices or documentation)\n\nBe specific with line numbers, provide code examples for suggested improvements, and explain the reasoning behind each recommendation."

          # Use jq to properly escape and insert the content
          jq --arg content "$CONTENT" '.messages[1].content = $content' request.json > final_request.json

          # Make the API call
          echo "üîç Making OpenAI API call..."
          echo "Request payload preview:"
          head -c 500 final_request.json

          # Debug: Check if API key is available (show only first/last 4 chars for security)
          if [ -z "$OPENAI_API_KEY" ]; then
            echo "‚ùå OPENAI_API_KEY secret is NOT set or is empty!"
          else
            API_KEY_LENGTH=${#OPENAI_API_KEY}
            if [ $API_KEY_LENGTH -gt 8 ]; then
              MASKED_KEY="${OPENAI_API_KEY:0:4}...${OPENAI_API_KEY: -4}"
              echo "‚úÖ OPENAI_API_KEY found (length: $API_KEY_LENGTH chars): $MASKED_KEY"
            else
              echo "‚ö†Ô∏è OPENAI_API_KEY found but seems too short (length: $API_KEY_LENGTH chars)"
            fi
          fi

          # Debug: Check OpenAI Project ID
          if [ -z "$OPENAI_PROJECT" ]; then
            echo "‚ùå OPENAIPROJECT secret is NOT set or is empty!"
          else
            echo "‚úÖ OPENAIPROJECT found: $OPENAI_PROJECT"
          fi

          # Prepare curl headers
          CURL_HEADERS=(-H "Authorization: Bearer $OPENAI_API_KEY" -H "Content-Type: application/json")

          # Add project header if available
          if [ ! -z "$OPENAI_PROJECT" ]; then
            CURL_HEADERS+=(-H "OpenAI-Project: $OPENAI_PROJECT")
          fi

          RESPONSE=$(curl -sS -X POST https://api.openai.com/v1/chat/completions \
            "${CURL_HEADERS[@]}" \
            --data @final_request.json)

          echo "üîç OpenAI API Response:"
          echo "$RESPONSE" | jq . || echo "Response is not valid JSON: $RESPONSE"

          # Check if we have a proper response
          if echo "$RESPONSE" | jq -e '.choices[0].message.content' > /dev/null 2>&1; then
            REVIEW_CONTENT=$(echo "$RESPONSE" | jq -r '.choices[0].message.content')
            echo "‚úÖ Successfully extracted AI review"
          else
            echo "‚ùå OpenAI API call failed or returned unexpected format"
            echo "Full response: $RESPONSE"
            
            # Check for common error patterns
            if echo "$RESPONSE" | jq -e '.error' > /dev/null 2>&1; then
              ERROR_MSG=$(echo "$RESPONSE" | jq -r '.error.message // .error')
              REVIEW_CONTENT="‚ùå OpenAI API Error: $ERROR_MSG"
            else
              REVIEW_CONTENT="‚ùå OpenAI API call failed - unexpected response format. Please check your API key and project settings."
            fi
          fi

          {
            echo "review<<EOF"
            echo "$REVIEW_CONTENT"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: Comment PR with AI Review
        uses: actions/github-script@v8
        with:
          script: |
            const review = process.env.AI_REVIEW || 'Code review not available';
            const body = `## üë®‚Äçüíª Code Review & Performance Analysis

            > **Automated code review by AI Senior Engineering Developer**
            > *Comprehensive static code analysis focusing on performance, quality, architecture, and best practices*

            ${review}

            ---
            *ü§ñ This review was generated using advanced AI analysis combining Lighthouse performance metrics with static code analysis*`;
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
        env:
          AI_REVIEW: ${{ steps.openai.outputs.review }}

      - name: Comment PR with results
        uses: actions/github-script@v8
        with:
          script: |
            const results = JSON.parse(`${{ steps.lighthouse.outputs.lighthouse_results }}`);
            // Calculate performance score percentage
            const perfScore = Math.round((results.Performance || 0) * 100);
            // Determine performance grade
            let grade = 'üî¥';
            if (perfScore >= 90) grade = 'üü¢';
            else if (perfScore >= 50) grade = 'üü°';
            // Check if there was an error
            const hasError = results.error || perfScore === 0;
            const comment = `## ü¶Ä Commit Crab Lighthouse Results ${hasError ? '‚ö†Ô∏è' : grade}
            **Performance Score: ${perfScore}/100**
            ${results.error ? `\n‚ö†Ô∏è **Error**: ${results.error}` : ''}
            ${results.Performance && results.Performance > 0 ? '' : '\n‚ö†Ô∏è *Note: This might be a local file test or there was an issue*'}
            ### Core Web Vitals
            | Metric | Value |
            |--------|--------|
            | **First Contentful Paint (FCP)** | ${results.FCP || 'N/A'} |
            | **Largest Contentful Paint (LCP)** | ${results.LCP || 'N/A'} |
            | **Cumulative Layout Shift (CLS)** | ${results.CLS || 'N/A'} |
            | **Total Blocking Time (TBT)** | ${results.TBT || 'N/A'} |
            | **Time to Interactive (TTI)** | ${results.TTI || 'N/A'} |
            ### Performance Recommendations
            ${hasError ? '‚ùå Unable to analyze performance due to errors. Check if the URL is accessible.' :
              perfScore >= 90 ? '‚úÖ Excellent performance! Keep up the good work.' :
              perfScore >= 50 ? '‚ö†Ô∏è Good performance, but there\'s room for improvement.' :
              '‚ùå Performance needs attention. Consider optimizing critical resources.'}
            ${`${{ steps.extract-url.outputs.is_local }}` === 'true' ? 
              '### üìÅ PR File Testing\n‚úÖ This test was run against the **production build** of your Pull Request!\n' : ''}
            ${hasError ? 
              '### üîß Troubleshooting\n- Ensure your dashboard\'s build command (`bun run build`) is working.\n- Check if the build output directory (`./dashboard/dist`) exists.\n- Verify that the built application runs without errors.\n' : ''}
            ---
            *Triggered by: @${{ github.event.comment.user.login }}*
            *URL tested: ${{ steps.lighthouse.outputs.target_url }}*
            *Commit: ${{ github.sha }}*
            `;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-results
          path: lighthouse-results.json
          retention-days: 30

      - name: Calculate Bundle Sizes
        id: bundle-sizes
        run: |
          echo "Calculating bundle sizes from build directory..."
          # Navigate to the build directory
          cd dashboard/dist

          # Calculate sizes in KB for different file types (using Linux stat command)
          JS_SIZE=$(find . -name "*.js" -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')
          CSS_SIZE=$(find . -name "*.css" -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Image files (jpg, jpeg, png, gif, svg, webp, ico)
          IMAGES_SIZE=$(find . \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -o -name "*.gif" -o -name "*.svg" -o -name "*.webp" -o -name "*.ico" \) -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Other files (excluding js, css, images)
          OTHERS_SIZE=$(find . ! \( -name "*.js" -o -name "*.css" -o -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -o -name "*.gif" -o -name "*.svg" -o -name "*.webp" -o -name "*.ico" \) -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Total build size
          TOTAL_SIZE=$(find . -type f -exec stat -c%s {} \; | awk '{sum+=$1} END {print int(sum/1024)}')

          # Handle empty values (set to 0 if no files found)
          JS_SIZE=${JS_SIZE:-0}
          CSS_SIZE=${CSS_SIZE:-0}
          IMAGES_SIZE=${IMAGES_SIZE:-0}
          OTHERS_SIZE=${OTHERS_SIZE:-0}
          TOTAL_SIZE=${TOTAL_SIZE:-0}

          echo "Bundle size breakdown:"
          echo "JavaScript: ${JS_SIZE} KB"
          echo "CSS: ${CSS_SIZE} KB"
          echo "Images: ${IMAGES_SIZE} KB"
          echo "Others: ${OTHERS_SIZE} KB"
          echo "Total: ${TOTAL_SIZE} KB"

          # Set outputs for the next step
          echo "js_size=${JS_SIZE}" >> $GITHUB_OUTPUT
          echo "css_size=${CSS_SIZE}" >> $GITHUB_OUTPUT
          echo "images_size=${IMAGES_SIZE}" >> $GITHUB_OUTPUT
          echo "others_size=${OTHERS_SIZE}" >> $GITHUB_OUTPUT
          echo "total_size=${TOTAL_SIZE}" >> $GITHUB_OUTPUT

          # Also create a detailed file listing for debugging
          echo "Detailed file listing:"
          find . -type f -exec ls -lh {} \; | sort -k5 -hr | head -20

      - name: Generate PR Performance JSON
        id: generate-json
        uses: actions/github-script@v8
        with:
          script: |
            // Parse lighthouse results
            const lighthouseResults = JSON.parse(`${{ steps.lighthouse.outputs.lighthouse_results }}`);

            // Get PR details from GitHub API
            const prData = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });

            // Get PR files changed
            const filesChanged = await github.rest.pulls.listFiles({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });

            // Calculate total lines changed from PR files
            let totalLinesAdded = 0;
            let totalLinesRemoved = 0;
            filesChanged.data.forEach(file => {
              totalLinesAdded += file.additions || 0;
              totalLinesRemoved += file.deletions || 0;
            });
            const totalLinesChanged = totalLinesAdded + totalLinesRemoved;

            // Extract vitals from lighthouse results (convert to numbers)
            const extractValue = (value) => {
              if (!value || value === 'N/A') return 0;
              // Extract numeric value from strings like "1.2 s" or "150 ms"
              const match = value.toString().match(/[\d.]+/);
              return match ? parseFloat(match[0]) : 0;
            };

            const vitals = {
              lcp: extractValue(lighthouseResults.LCP),
              tbt: extractValue(lighthouseResults.TBT), 
              cls: extractValue(lighthouseResults.CLS),
              fcp: extractValue(lighthouseResults.FCP),
              si: 0, // Speed Index not captured in current setup
              tti: extractValue(lighthouseResults.TTI)
            };

            // Calculate average score (excluding SI since it's not available)
            const vitalsAvgScore = Math.round((lighthouseResults.Performance || 0) * 100);

            // Create the JSON structure with real PR data
            const prNumber = context.issue.number;
            const prPerformanceData = {
              [prNumber]: {
                prnumber: prNumber,
                title: prData.data.title || "PR Title Not Available",
                filesChanged: filesChanged.data.length || 0,
                linesAdded: totalLinesAdded,
                linesRemoved: totalLinesRemoved,
                totalLinesChanged: totalLinesChanged,
                prURL: prData.data.html_url || "",
                prDesc: prData.data.body || "",
                vitalsAvgScore: vitalsAvgScore,
                raisedBy: prData.data.user.login || "",
                PRCreatedOn: prData.data.created_at || "",
                reviewers: prData.data.requested_reviewers?.map(r => r.login) || [],
                vitals: vitals,
                bundleSize: {
                  js: parseInt(`${{ steps.bundle-sizes.outputs.js_size }}`) || 0,
                  css: parseInt(`${{ steps.bundle-sizes.outputs.css_size }}`) || 0,
                  images: parseInt(`${{ steps.bundle-sizes.outputs.images_size }}`) || 0,
                  others: parseInt(`${{ steps.bundle-sizes.outputs.others_size }}`) || 0
                },
                totalBuildSize: `${{ steps.bundle-sizes.outputs.total_size }} KB`
              }
            };

            console.log('Generated PR Performance Data:');
            console.log(JSON.stringify(prPerformanceData, null, 2));

            // Set output for the curl step
            core.setOutput('json_data', JSON.stringify(prPerformanceData));

      - name: Send Data to JSONBin
        run: |
          echo "Sending performance data to JSONBin..."

          # Get existing data first
          echo "Fetching existing data..."
          EXISTING_DATA=$(curl -s \
            -H "X-Access-key: \$2a\$10\$wF2lmZTq.Xrr1IRJd2Mbu.iYxaYo0Lswkx7ZE/kUuMUkq2fFxuI06" \
            --request GET \
            https://api.jsonbin.io/v3/b/68cd6b53d0ea881f40833212)

          # Extract the record data (JSONBin wraps data in metadata)
          EXISTING_RECORD=$(echo "$EXISTING_DATA" | jq -r '.record // {}')

          # Get new data from previous step
          NEW_DATA='${{ steps.generate-json.outputs.json_data }}'

          echo "New data to append:"
          echo "$NEW_DATA" | jq .

          # Append/merge the new PR data with existing records under the record key
          MERGED_RECORD=$(jq -n --argjson existing "$EXISTING_RECORD" --argjson new "$NEW_DATA" '$existing * $new')

          echo "Merged record data:"
          echo "$MERGED_RECORD" | jq .

          # Send the merged record data by piping it to curl's stdin
          RESPONSE=$(echo "$MERGED_RECORD" | curl -s \
            -H "Content-Type: application/json" \
            -H "X-Access-key: \$2a\$10\$wF2lmZTq.Xrr1IRJd2Mbu.iYxaYo0Lswkx7ZE/kUuMUkq2fFxuI06" \
            --request PUT \
            --data @- \
            https://api.jsonbin.io/v3/b/68cd6b53d0ea881f40833212)

          echo "JSONBin Response:"
          echo "$RESPONSE" | jq .

          if echo "$RESPONSE" | jq -e '.record' > /dev/null; then
            echo "‚úÖ Performance data successfully sent to JSONBin"
          else
            echo "‚ùå Failed to send data to JSONBin"
            echo "Response details:"
            echo "$RESPONSE"
          fi

      - name: Cleanup
        if: always()
        run: |
          # Kill the local server if it's running
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID 2>/dev/null || echo "Server already stopped"
          fi
